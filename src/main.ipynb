{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5c149106",
      "metadata": {
        "id": "5c149106"
      },
      "source": [
        "# 모델 돌리기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt9qj8687NxP",
        "outputId": "60d69d03-f538-47de-8443-af11256b3c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "id": "Pt9qj8687NxP"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 드라이브 내에 폴더 경로 설정\n",
        "drive_folder_path = '/content/sample_data/image1vs1'\n",
        "\n",
        "# 폴더 생성\n",
        "os.makedirs(drive_folder_path, exist_ok=True)\n",
        "\n",
        "%cd /content/sample_data/image1vs1\n",
        "\n",
        "!unzip -qq \"/content/drive/MyDrive/Colab Notebooks/EANN - (src에 코드)/Data/image1vs1.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtIeHdoOlCrM",
        "outputId": "4762a9ca-762d-411d-91ce-3e0cebc9a401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample_data/image1vs1\n"
          ]
        }
      ],
      "id": "FtIeHdoOlCrM"
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "filepaths = glob.glob('/content/sample_data/image1vs1/*')\n",
        "print(f\"Number of images found: {len(filepaths)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8Gtzytlme1O",
        "outputId": "c451c859-47be-48e6-b80b-5b062a61c356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images found: 6238\n"
          ]
        }
      ],
      "id": "U8Gtzytlme1O"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ipynb"
      ],
      "metadata": {
        "id": "wGUb-RRyCyU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7722a5c2-c93f-4c72-a14e-daa4f99c38bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipynb\n",
            "  Downloading ipynb-0.5.1-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: ipynb\n",
            "Successfully installed ipynb-0.5.1\n"
          ]
        }
      ],
      "id": "wGUb-RRyCyU6"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N-q3KZfNM_i",
        "outputId": "cbde5944-c9b5-4914-c981-d4b0e93343cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"
          ]
        }
      ],
      "id": "7N-q3KZfNM_i"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/EANN - (src에 코드)/src\n",
        "\n",
        "import ipynb\n",
        "import importlib\n",
        "import process_data_coupang"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPay-kHPJP39",
        "outputId": "225d4671-40ad-474a-ab68-f4b0b16e1a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/EANN - (src에 코드)/src\n"
          ]
        }
      ],
      "id": "MPay-kHPJP39"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4568ace",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4568ace",
        "outputId": "e00703d7-802f-4190-b02d-c6e2a8457a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data\n",
            "Text and image\n",
            "Image length 6238\n",
            "Original post length is 3821\n",
            "Original data frame is (3821, 14)\n",
            "Sponsored :1867\n",
            "Non Sponsored :1954\n",
            "-------------------------------------\n",
            "data size is 3821\n",
            "paired post length is 3821\n",
            "paried data has 16 dimension\n",
            "Original post length is 1175\n",
            "Original data frame is (1175, 14)\n",
            "Sponsored :574\n",
            "Non Sponsored :601\n",
            "-------------------------------------\n",
            "data size is 1175\n",
            "paired post length is 1175\n",
            "paried data has 16 dimension\n",
            "Original post length is 1242\n",
            "Original data frame is (1242, 14)\n",
            "Sponsored :678\n",
            "Non Sponsored :564\n",
            "-------------------------------------\n",
            "data size is 1242\n",
            "paired post length is 1242\n",
            "paried data has 16 dimension\n",
            "loading data...\n",
            "number of sentences: 6238\n",
            "vocab size: 48299\n",
            "max sentence length: 3455\n",
            "word2vec loaded!\n",
            "num words already in word2vec: 4626\n",
            "translate data to embedding\n",
            "translate test data to embedding\n",
            "sequence length 250\n",
            "Train Data Size is 3821\n",
            "Finished loading data \n",
            "TEXT: 3821, Image: 3821, label: 3821, Event: 3821\n",
            "TEXT: 1175, Image: 1175, label: 1175, Event: 1175\n",
            "TEXT: 1242, Image: 1242, label: 1242, Event: 1242\n",
            "building model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:08<00:00, 66.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA\n",
            "loader size 60\n",
            "training model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30],  Loss: 0.6608, Class Loss: 0.6608, Train_Acc: 0.5825,  Validate_Acc: 0.6886.\n",
            "Epoch [2/30],  Loss: 0.6143, Class Loss: 0.6143, Train_Acc: 0.6288,  Validate_Acc: 0.8331.\n",
            "Epoch [3/30],  Loss: 0.5763, Class Loss: 0.5763, Train_Acc: 0.6745,  Validate_Acc: 0.8708.\n",
            "Epoch [4/30],  Loss: 0.5632, Class Loss: 0.5632, Train_Acc: 0.6935,  Validate_Acc: 0.8940.\n",
            "Epoch [5/30],  Loss: 0.5475, Class Loss: 0.5475, Train_Acc: 0.7118,  Validate_Acc: 0.9189.\n",
            "Epoch [6/30],  Loss: 0.5378, Class Loss: 0.5378, Train_Acc: 0.7235,  Validate_Acc: 0.9273.\n",
            "Epoch [7/30],  Loss: 0.5343, Class Loss: 0.5343, Train_Acc: 0.7156,  Validate_Acc: 0.9305.\n",
            "Epoch [8/30],  Loss: 0.5317, Class Loss: 0.5317, Train_Acc: 0.7360,  Validate_Acc: 0.9451.\n",
            "Epoch [9/30],  Loss: 0.5316, Class Loss: 0.5316, Train_Acc: 0.7227,  Validate_Acc: 0.9372.\n",
            "Epoch [10/30],  Loss: 0.5273, Class Loss: 0.5273, Train_Acc: 0.7301,  Validate_Acc: 0.9395.\n",
            "Epoch [11/30],  Loss: 0.5211, Class Loss: 0.5211, Train_Acc: 0.7438,  Validate_Acc: 0.9421.\n",
            "Epoch [12/30],  Loss: 0.5223, Class Loss: 0.5223, Train_Acc: 0.7363,  Validate_Acc: 0.9329.\n",
            "Epoch [13/30],  Loss: 0.5257, Class Loss: 0.5257, Train_Acc: 0.7345,  Validate_Acc: 0.9469.\n",
            "Epoch [14/30],  Loss: 0.5223, Class Loss: 0.5223, Train_Acc: 0.7410,  Validate_Acc: 0.9477.\n",
            "Epoch [15/30],  Loss: 0.5210, Class Loss: 0.5210, Train_Acc: 0.7384,  Validate_Acc: 0.9428.\n",
            "Epoch [16/30],  Loss: 0.5137, Class Loss: 0.5137, Train_Acc: 0.7450,  Validate_Acc: 0.9479.\n",
            "Epoch [17/30],  Loss: 0.5139, Class Loss: 0.5139, Train_Acc: 0.7452,  Validate_Acc: 0.9446.\n",
            "Epoch [18/30],  Loss: 0.5127, Class Loss: 0.5127, Train_Acc: 0.7418,  Validate_Acc: 0.9485.\n",
            "Epoch [19/30],  Loss: 0.5151, Class Loss: 0.5151, Train_Acc: 0.7408,  Validate_Acc: 0.9469.\n",
            "Epoch [20/30],  Loss: 0.5116, Class Loss: 0.5116, Train_Acc: 0.7488,  Validate_Acc: 0.9477.\n",
            "Epoch [21/30],  Loss: 0.5121, Class Loss: 0.5121, Train_Acc: 0.7462,  Validate_Acc: 0.9520.\n",
            "Epoch [22/30],  Loss: 0.5155, Class Loss: 0.5155, Train_Acc: 0.7444,  Validate_Acc: 0.9504.\n",
            "Epoch [23/30],  Loss: 0.5171, Class Loss: 0.5171, Train_Acc: 0.7398,  Validate_Acc: 0.9517.\n",
            "Epoch [24/30],  Loss: 0.5076, Class Loss: 0.5076, Train_Acc: 0.7548,  Validate_Acc: 0.9533.\n",
            "Epoch [25/30],  Loss: 0.5126, Class Loss: 0.5126, Train_Acc: 0.7527,  Validate_Acc: 0.9518.\n",
            "Epoch [26/30],  Loss: 0.5070, Class Loss: 0.5070, Train_Acc: 0.7551,  Validate_Acc: 0.9510.\n",
            "Epoch [27/30],  Loss: 0.5107, Class Loss: 0.5107, Train_Acc: 0.7517,  Validate_Acc: 0.9494.\n",
            "Epoch [28/30],  Loss: 0.5113, Class Loss: 0.5113, Train_Acc: 0.7455,  Validate_Acc: 0.9494.\n",
            "Epoch [29/30],  Loss: 0.5091, Class Loss: 0.5091, Train_Acc: 0.7448,  Validate_Acc: 0.9549.\n",
            "Epoch [30/30],  Loss: 0.5075, Class Loss: 0.5075, Train_Acc: 0.7475,  Validate_Acc: 0.9492.\n",
            "testing model\n",
            "Classification Acc: 0.9340, AUC-ROC: 0.9802\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.93      0.93       564\n",
            "           1       0.94      0.94      0.94       678\n",
            "\n",
            "    accuracy                           0.93      1242\n",
            "   macro avg       0.93      0.93      0.93      1242\n",
            "weighted avg       0.93      0.93      0.93      1242\n",
            "\n",
            "\n",
            "Classification confusion matrix:\n",
            "[[525  39]\n",
            " [ 43 635]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import time, os\n",
        "# import random\n",
        "import process_data_coupang as process_data\n",
        "import copy\n",
        "import pickle\n",
        "from random import sample\n",
        "import torchvision\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import StepLR, MultiStepLR, ExponentialLR\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable, Function\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.autograd import Function\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models.vgg import VGG19_Weights\n",
        "\n",
        "#from logger import Logger\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import scipy.io as sio\n",
        "\n",
        "class Rumor_Data(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.text = torch.from_numpy(np.array(dataset['post_text']))\n",
        "        self.image = list(dataset['image'])\n",
        "        #self.social_context = torch.from_numpy(np.array(dataset['social_feature']))\n",
        "        self.mask = torch.from_numpy(np.array(dataset['mask']))\n",
        "        self.label = torch.from_numpy(np.array(dataset['label']))\n",
        "        self.event_label = torch.from_numpy(np.array(dataset['event_label']))\n",
        "\n",
        "        # 추가 feature\n",
        "        self.img_num = torch.from_numpy(np.array(dataset['img_num']))\n",
        "        self.title1 = torch.from_numpy(np.array(dataset['title1']))\n",
        "        self.helpfulness = torch.from_numpy(np.array(dataset['helpfulness']))\n",
        "        self.rate = torch.from_numpy(np.array(dataset['rate']))\n",
        "        self.top_reviewer = torch.from_numpy(np.array(dataset['top_reviewer']))\n",
        "        self.realname_reviewer = torch.from_numpy(np.array(dataset['realname_reviewer']))\n",
        "        self.review_num = torch.from_numpy(np.array(dataset['review_num']))\n",
        "        self.line_breaks = torch.from_numpy(np.array(dataset['line_breaks']))\n",
        "\n",
        "        # 모든 추가 피처들을 하나의 어레이로 결합\n",
        "        self.additional_features = torch.from_numpy(np.vstack([\n",
        "            # Review Meta\n",
        "            np.array(dataset['img_num']), np.array(dataset['title1']), np.array(dataset['helpfulness']),\n",
        "            np.array(dataset['rate']), np.array(dataset['review_num']), np.array(dataset['line_breaks']),\n",
        "            # Reviewer Meta\n",
        "            np.array(dataset['top_reviewer']), np.array(dataset['realname_reviewer'])\n",
        "        ]).astype(np.float32).T)\n",
        "\n",
        "        print('TEXT: %d, Image: %d, label: %d, Event: %d'\n",
        "               % (len(self.text), len(self.image), len(self.label), len(self.event_label)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # return (self.text[idx], self.image[idx], self.mask[idx]), self.label[idx], self.event_label[idx]\n",
        "        return (self.text[idx], self.image[idx], self.additional_features[idx], self.mask[idx]), self.label[idx], self.event_label[idx]\n",
        "\n",
        "\n",
        "class ReverseLayerF(Function):\n",
        "    #staticmethod\n",
        "    def forward(ctx, x, alpha=1.0):\n",
        "        ctx.alpha = alpha\n",
        "        return x.view_as(x)\n",
        "\n",
        "    #staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "        return output, None\n",
        "\n",
        "\n",
        "def grad_reverse(x):\n",
        "    return ReverseLayerF()(x)\n",
        "\n",
        "# Neural Network Model (1 hidden layer)\n",
        "class CNN_Fusion(nn.Module):\n",
        "    def __init__(self, args, W):\n",
        "        super(CNN_Fusion, self).__init__()\n",
        "        self.args = args\n",
        "\n",
        "        self.event_num = args.event_num\n",
        "\n",
        "        vocab_size = args.vocab_size\n",
        "        emb_dim = args.embed_dim\n",
        "\n",
        "        C = args.class_num\n",
        "        self.hidden_size = args.hidden_dim\n",
        "        self.lstm_size = args.embed_dim\n",
        "        self.social_size = 19\n",
        "\n",
        "        # TEXT RNN\n",
        "        self.embed = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.embed.weight = nn.Parameter(torch.from_numpy(W))\n",
        "        self.lstm = nn.LSTM(self.lstm_size, self.lstm_size)\n",
        "        self.text_fc = nn.Linear(self.lstm_size, self.hidden_size)\n",
        "        self.text_encoder = nn.Linear(emb_dim, self.hidden_size)\n",
        "\n",
        "        ### TEXT CNN\n",
        "        channel_in = 1\n",
        "        filter_num = 20\n",
        "        window_size = [1, 2, 3, 4]\n",
        "        self.convs = nn.ModuleList([nn.Conv2d(channel_in, filter_num, (K, emb_dim)) for K in window_size])\n",
        "        self.fc1 = nn.Linear(len(window_size) * filter_num, self.hidden_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(args.dropout)\n",
        "\n",
        "        #IMAGE\n",
        "        #hidden_size = args.hidden_dim\n",
        "        vgg_19 = torchvision.models.vgg19(weights=VGG19_Weights.IMAGENET1K_V1)\n",
        "        for param in vgg_19.parameters():\n",
        "            param.requires_grad = False\n",
        "        # visual model\n",
        "        num_ftrs = vgg_19.classifier._modules['6'].out_features\n",
        "        self.vgg = vgg_19\n",
        "        self.image_fc1 = nn.Linear(num_ftrs,  self.hidden_size)\n",
        "        #self.image_fc2 = nn.Linear(512, self.hidden_size)\n",
        "        self.image_adv = nn.Linear(self.hidden_size,  int(self.hidden_size))\n",
        "        self.image_encoder = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "\n",
        "\n",
        "        ### additional feature\n",
        "        # self.social = nn.Linear(self.social_size, self.hidden_size)\n",
        "        #self.img_num_fc = nn.Linear(1, int(self.hidden_size))\n",
        "        self.additional_features_fc = nn.Sequential(\n",
        "            # additional feature 열 개수 변경 시 다음 parameter 조정 필요\n",
        "            nn.Linear(8, args.additional_dim),\n",
        "            nn.BatchNorm1d(args.additional_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(args.dropout)\n",
        "        )\n",
        "\n",
        "        ## ATTENTION\n",
        "        self.attention_layer = nn.Linear(self.hidden_size, emb_dim)\n",
        "\n",
        "        ## Class Classifier\n",
        "        self.class_classifier = nn.Sequential()\n",
        "        self.class_classifier.add_module('c_fc1', nn.Linear(2 * self.hidden_size + args.additional_dim, 2))\n",
        "        self.class_classifier.add_module('c_relu1', nn.ReLU(True))\n",
        "        self.class_classifier.add_module('c_drop1', nn.Dropout(args.dropout))\n",
        "        #self.class_classifier.add_module('c_fc2', nn.Linear(self.hidden_size, 2))\n",
        "        #self.class_classifier.add_module('c_bn2', nn.BatchNorm2d(self.hidden_size))\n",
        "        #self.class_classifier.add_module('c_relu2', nn.ReLU(True))\n",
        "        #self.class_classifier.add_module('c_fc3', nn.Linear(100, 10))\n",
        "        self.class_classifier.add_module('c_softmax', nn.Softmax(dim=1))\n",
        "\n",
        "        ### Catefory Classifier\n",
        "        self.domain_classifier = nn.Sequential()\n",
        "        self.domain_classifier.add_module('d_fc1', nn.Linear(2 * self.hidden_size + args.additional_dim, self.hidden_size))\n",
        "        #self.domain_classifier.add_module('d_bn1', nn.BatchNorm2d(self.hidden_size))\n",
        "        self.domain_classifier.add_module('d_relu1', nn.LeakyReLU(True))\n",
        "        self.domain_classifier.add_module('d_fc2', nn.Linear(self.hidden_size, self.event_num))\n",
        "        self.domain_classifier.add_module('d_softmax', nn.Softmax(dim=1))\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # Before we've done anything, we dont have any hidden state.\n",
        "        # Refer to the Pytorch documentation to see exactly\n",
        "        # why they have this dimensionality.\n",
        "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
        "        return (to_var(torch.zeros(1, batch_size, self.lstm_size)),\n",
        "                to_var(torch.zeros(1, batch_size, self.lstm_size)))\n",
        "\n",
        "    def conv_and_pool(self, x, conv):\n",
        "        x = F.relu(conv(x)).squeeze(3)  # (sample number,hidden_dim, length)\n",
        "        #x = F.avg_pool1d(x, x.size(2)).squeeze(2)\n",
        "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, text, image, additional_features, mask):\n",
        "        ### IMAGE #####\n",
        "        image = self.vgg(image) #[N, 512]\n",
        "        image = F.leaky_relu(self.image_fc1(image))\n",
        "\n",
        "        ##########CNN##################\n",
        "        text = self.embed(text)\n",
        "        text = text * mask.unsqueeze(2).expand_as(text)\n",
        "        text = text.unsqueeze(1)\n",
        "        text = [F.leaky_relu(conv(text)).squeeze(3) for conv in self.convs]  # [(N,hidden_dim,W), ...]*len(window_size)\n",
        "        #text = [F.avg_pool1d(i, i.size(2)).squeeze(2) for i in text]  # [(N,hidden_dim), ...]*len(window_size)\n",
        "        text = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in text]\n",
        "        text = torch.cat(text, 1)\n",
        "        text = F.leaky_relu(self.fc1(text))\n",
        "\n",
        "        ###########Additional Feature############\n",
        "        additional_features = additional_features.float()\n",
        "        additional_features = self.additional_features_fc(additional_features)\n",
        "\n",
        "        text_image = torch.cat((text, image, additional_features), 1)\n",
        "        #text_image = torch.cat((text, image), 1)\n",
        "\n",
        "        ### Fake or real\n",
        "        class_output = self.class_classifier(text_image)\n",
        "        ## Domain (which Category)\n",
        "        reverse_feature = ReverseLayerF.apply(text_image)\n",
        "        # reverse_feature = grad_reverse(text_image)\n",
        "        # domain_output = self.domain_classifier(reverse_feature)\n",
        "\n",
        "        # ### Multimodal\n",
        "        # text_reverse_feature = grad_reverse(text)\n",
        "        # image_reverse_feature = grad_reverse(image)\n",
        "        # text_output = self.modal_classifier(text_reverse_feature)\n",
        "        # image_output = self.modal_classifier(image_reverse_feature\n",
        "        return class_output # , domain_output\n",
        "\n",
        "def to_var(x):\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return Variable(x)\n",
        "\n",
        "def to_np(x):\n",
        "    return x.data.cpu().numpy()\n",
        "\n",
        "def select(train, selec_indices):\n",
        "    temp = []\n",
        "    for i in range(len(train)):\n",
        "        print(\"length is \"+str(len(train[i])))\n",
        "        print(i)\n",
        "        #print(train[i])\n",
        "        ele = list(train[i])\n",
        "        temp.append([ele[i] for i in selec_indices])\n",
        "    return temp\n",
        "\n",
        "def make_weights_for_balanced_classes(event, nclasses = 15):\n",
        "    count = [0] * nclasses\n",
        "    for item in event:\n",
        "        count[item] += 1\n",
        "    weight_per_class = [0.] * nclasses\n",
        "    N = float(sum(count))\n",
        "    for i in range(nclasses):\n",
        "        weight_per_class[i] = N/float(count[i])\n",
        "    weight = [0] * len(event)\n",
        "    for idx, val in enumerate(event):\n",
        "        weight[idx] = weight_per_class[val]\n",
        "    return weight\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    print('loading data')\n",
        "    #    dataset = DiabetesDataset(root=args.training_file)\n",
        "    #    train_loader = DataLoader(dataset=dataset,\n",
        "    #                              batch_size=32,\n",
        "    #                              shuffle=True,\n",
        "    #                              num_workers=2)\n",
        "\n",
        "    # MNIST Dataset\n",
        "    train, validation, test, W = load_data(args)\n",
        "    test_id = test['post_id']\n",
        "\n",
        "    #train, validation = split_train_validation(train,  1)\n",
        "\n",
        "    #weights = make_weights_for_balanced_classes(train[-1], 15)\n",
        "    #weights = torch.DoubleTensor(weights)\n",
        "    #sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n",
        "\n",
        "\n",
        "    train_dataset = Rumor_Data(train)\n",
        "\n",
        "    validate_dataset = Rumor_Data(validation)\n",
        "\n",
        "    test_dataset = Rumor_Data(test)\n",
        "\n",
        "    # Data Loader (Input Pipeline)\n",
        "    train_loader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=args.batch_size,\n",
        "                              shuffle=True)\n",
        "\n",
        "    validate_loader = DataLoader(dataset = validate_dataset,\n",
        "                                 batch_size=args.batch_size,\n",
        "                                 shuffle=False)\n",
        "\n",
        "    test_loader = DataLoader(dataset=test_dataset,\n",
        "                             batch_size=args.batch_size,\n",
        "                             shuffle=False)\n",
        "\n",
        "    print('building model')\n",
        "    model = CNN_Fusion(args, W)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"CUDA\")\n",
        "        model.cuda()\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, list(model.parameters())),\n",
        "                                 lr= args.learning_rate)\n",
        "    #optimizer = torch.optim.RMSprop(filter(lambda p: p.requires_grad, list(model.parameters())),\n",
        "                                 #lr=args.learning_rate)\n",
        "    #scheduler = StepLR(optimizer, step_size= 10, gamma= 1)\n",
        "\n",
        "\n",
        "    iter_per_epoch = len(train_loader)\n",
        "    print(\"loader size \" + str(len(train_loader)))\n",
        "    best_validate_acc = 0.000\n",
        "    best_test_acc = 0.000\n",
        "    best_loss = 100\n",
        "    best_validate_dir = ''\n",
        "    best_list = [0,0]\n",
        "\n",
        "    print('training model')\n",
        "    adversarial = True\n",
        "    # Train the Model\n",
        "    for epoch in range(args.num_epochs):\n",
        "\n",
        "        p = float(epoch) / 100\n",
        "        #lambd = 2. / (1. + np.exp(-10. * p)) - 1\n",
        "        lr = 0.001 / (1. + 10 * p) ** 0.75\n",
        "\n",
        "        optimizer.lr = lr\n",
        "        #rgs.lambd = lambd\n",
        "        start_time = time.time()\n",
        "        cost_vector = []\n",
        "        class_cost_vector = []\n",
        "        domain_cost_vector = []\n",
        "        acc_vector = []\n",
        "        valid_acc_vector = []\n",
        "        test_acc_vector = []\n",
        "        vali_cost_vector = []\n",
        "        test_cost_vector = []\n",
        "\n",
        "        for i, (train_data, train_labels, event_labels) in enumerate(train_loader):\n",
        "            train_text, train_image, train_add, train_mask, train_labels, event_labels = \\\n",
        "                to_var(train_data[0]), to_var(train_data[1]), to_var(train_data[2]), to_var(train_data[3]), \\\n",
        "                to_var(train_labels), to_var(event_labels)\n",
        "\n",
        "            # Forward + Backward + Optimize\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            class_outputs = model(train_text, train_image, train_add, train_mask)\n",
        "\n",
        "            ## Fake or Real loss\n",
        "            class_loss = criterion(class_outputs, train_labels.long())\n",
        "\n",
        "            # Event Loss\n",
        "            # domain_loss = criterion(domain_outputs, event_labels.long())\n",
        "\n",
        "            loss = class_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            _, argmax = torch.max(class_outputs, 1)\n",
        "\n",
        "            cross_entropy = True\n",
        "\n",
        "            if True:\n",
        "                accuracy = (train_labels == argmax.squeeze()).float().mean()\n",
        "            else:\n",
        "                _, labels = torch.max(train_labels, 1)\n",
        "                accuracy = (labels.squeeze() == argmax.squeeze()).float().mean()\n",
        "\n",
        "            #class_cost_vector.append(class_loss.data[0])\n",
        "            class_cost_vector.append(class_loss.item())\n",
        "            #domain_cost_vector.append(domain_loss.data[0])\n",
        "            # domain_cost_vector.append(domain_loss.item())\n",
        "\n",
        "            #cost_vector.append(loss.data[0])\n",
        "            cost_vector.append(loss.item())\n",
        "\n",
        "            #acc_vector.append(accuracy.data[0])\n",
        "            acc_vector.append(accuracy.item())\n",
        "\n",
        "\n",
        "            # if i == 0:\n",
        "            #     train_score = to_np(class_outputs.squeeze())\n",
        "            #     train_pred = to_np(argmax.squeeze())\n",
        "            #     train_true = to_np(train_labels.squeeze())\n",
        "            # else:\n",
        "            #     class_score = np.concatenate((train_score, to_np(class_outputs.squeeze())), axis=0)\n",
        "            #     train_pred = np.concatenate((train_pred, to_np(argmax.squeeze())), axis=0)\n",
        "            #     train_true = np.concatenate((train_true, to_np(train_labels.squeeze())), axis=0)\n",
        "\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        validate_acc_vector_temp = []\n",
        "        for i, (validate_data, validate_labels, event_labels) in enumerate(validate_loader):\n",
        "            validate_text, validate_image, validate_add, validate_mask, validate_labels, event_labels = \\\n",
        "                to_var(validate_data[0]), to_var(validate_data[1]), to_var(validate_data[2]), to_var(validate_data[3]), \\\n",
        "                to_var(validate_labels), to_var(event_labels)\n",
        "            validate_outputs = model(validate_text, validate_image, validate_add, validate_mask)\n",
        "            _, validate_argmax = torch.max(validate_outputs, 1)\n",
        "            vali_loss = criterion(validate_outputs, validate_labels.long())\n",
        "            #domain_loss = criterion(domain_outputs, event_labels)\n",
        "                #_, labels = torch.max(validate_labels, 1)\n",
        "            validate_accuracy = (validate_labels == validate_argmax.squeeze()).float().mean()\n",
        "            #vali_cost_vector.append( vali_loss.data[0])\n",
        "            vali_cost_vector.append( vali_loss.item())\n",
        "                #validate_accuracy = (validate_labels == validate_argmax.squeeze()).float().mean()\n",
        "\n",
        "            #validate_acc_vector_temp.append(validate_accuracy.data[0])\n",
        "            validate_acc_vector_temp.append(validate_accuracy.item())\n",
        "        validate_acc = np.mean(validate_acc_vector_temp)\n",
        "        valid_acc_vector.append(validate_acc)\n",
        "        model.train()\n",
        "        print ('Epoch [%d/%d],  Loss: %.4f, Class Loss: %.4f, Train_Acc: %.4f,  Validate_Acc: %.4f.'\n",
        "                % (\n",
        "                epoch + 1, args.num_epochs,  np.mean(cost_vector), np.mean(class_cost_vector),\n",
        "                    np.mean(acc_vector),   validate_acc))\n",
        "\n",
        "        if validate_acc > best_validate_acc:\n",
        "            best_validate_acc = validate_acc\n",
        "            if not os.path.exists(args.output_file):\n",
        "                os.mkdir(args.output_file)\n",
        "\n",
        "            best_validate_dir = args.output_file + str(epoch + 1) + '.pkl'\n",
        "            torch.save(model.state_dict(), best_validate_dir)\n",
        "\n",
        "        duration = time.time() - start_time\n",
        "        # print ('Epoch: %d, Mean_Cost: %.4f, Duration: %.4f, Mean_Train_Acc: %.4f, Mean_Test_Acc: %.4f'\n",
        "        # % (epoch + 1, np.mean(cost_vector), duration, np.mean(acc_vector), np.mean(test_acc_vector)))\n",
        "        # best_validate_dir = args.output_file + 'weibo_GPU2_out.' + str(52) + '.pkl'\n",
        "\n",
        "\n",
        "\n",
        "    # Test the Model\n",
        "    print('testing model')\n",
        "    model = CNN_Fusion(args, W)\n",
        "    model.load_state_dict(torch.load(best_validate_dir))\n",
        "    #    print(torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "    model.eval()\n",
        "    test_score = []\n",
        "    test_pred = []\n",
        "    test_true = []\n",
        "    for i, (test_data, test_labels, event_labels) in enumerate(test_loader):\n",
        "        test_text, test_image, test_add, test_mask, test_labels = to_var(\n",
        "            test_data[0]), to_var(test_data[1]), to_var(test_data[2]), to_var(test_data[3]), to_var(test_labels)\n",
        "        test_outputs = model(test_text, test_image, test_add, test_mask)\n",
        "        _, test_argmax = torch.max(test_outputs, 1)\n",
        "        if i == 0:\n",
        "            test_score = to_np(test_outputs.squeeze())\n",
        "            test_pred = to_np(test_argmax.squeeze())\n",
        "            test_true = to_np(test_labels.squeeze())\n",
        "        else:\n",
        "            test_score = np.concatenate((test_score, to_np(test_outputs.squeeze())), axis=0)\n",
        "            test_pred = np.concatenate((test_pred, to_np(test_argmax.squeeze())), axis=0)\n",
        "            test_true = np.concatenate((test_true, to_np(test_labels.squeeze())), axis=0)\n",
        "\n",
        "    test_accuracy = metrics.accuracy_score(test_true, test_pred)\n",
        "    test_f1 = metrics.f1_score(test_true, test_pred, average='macro')\n",
        "    test_precision = metrics.precision_score(test_true, test_pred, average='macro')\n",
        "    test_recall = metrics.recall_score(test_true, test_pred, average='macro')\n",
        "    test_score_convert = [x[1] for x in test_score]\n",
        "    test_aucroc = metrics.roc_auc_score(test_true, test_score_convert, average='macro')\n",
        "\n",
        "    test_confusion_matrix = metrics.confusion_matrix(test_true, test_pred)\n",
        "\n",
        "    print(\"Classification Acc: %.4f, AUC-ROC: %.4f\"\n",
        "          % (test_accuracy, test_aucroc))\n",
        "    print(\"Classification report:\\n%s\\n\"\n",
        "          % (metrics.classification_report(test_true, test_pred)))\n",
        "    print(\"Classification confusion matrix:\\n%s\\n\"\n",
        "          % (test_confusion_matrix))\n",
        "\n",
        "\n",
        "def parse_arguments(parser):\n",
        "    parser.add_argument('training_file', type=str, metavar='<training_file>', help='')\n",
        "    #parser.add_argument('validation_file', type=str, metavar='<validation_file>', help='')\n",
        "    parser.add_argument('testing_file', type=str, metavar='<testing_file>', help='')\n",
        "    parser.add_argument('output_file', type=str, metavar='<output_file>', help='')\n",
        "\n",
        "    parse.add_argument('--static', type=bool, default=True, help='')\n",
        "    parser.add_argument('--sequence_length', type=int, default= 250, help='')\n",
        "    ##### parser.add_argument('--sequence_length', type=int, default= 28, help='')\n",
        "    parser.add_argument('--class_num', type=int, default=2, help='')\n",
        "    parser.add_argument('--hidden_dim', type=int, default = 128, help='')\n",
        "    parser.add_argument('--embed_dim', type=int, default=32, help='')\n",
        "    parser.add_argument('--additional_dim', type=int, default = 64, help='')\n",
        "    parser.add_argument('--vocab_size', type=int, default=300, help='')\n",
        "    parser.add_argument('--dropout', type=int, default=0.5, help='')\n",
        "    parser.add_argument('--filter_num', type=int, default=5, help='')\n",
        "    parser.add_argument('--lambd', type=int, default= 1, help='')\n",
        "    parser.add_argument('--text_only', type=bool, default= False, help='')\n",
        "\n",
        "    #    parser.add_argument('--sequence_length', type = int, default = 28, help = '')\n",
        "    #    parser.add_argument('--input_size', type = int, default = 28, help = '')\n",
        "    #    parser.add_argument('--hidden_size', type = int, default = 128, help = '')\n",
        "    #    parser.add_argument('--num_layers', type = int, default = 2, help = '')\n",
        "    #    parser.add_argument('--num_classes', type = int, default = 10, help = '')\n",
        "    parser.add_argument('--d_iter', type=int, default = 3, help='')\n",
        "    parser.add_argument('--batch_size', type=int, default = 64, help='')\n",
        "    parser.add_argument('--num_epochs', type=int, default = 30, help='')\n",
        "    parser.add_argument('--learning_rate', type=float, default = 0.0005, help='')\n",
        "    parser.add_argument('--event_num', type=int, default = 60, help='')\n",
        "\n",
        "\n",
        "    #    args = parser.parse_args()\n",
        "    return parser\n",
        "\n",
        "def word2vec(post, word_id_map, W):\n",
        "    word_embedding = []\n",
        "    mask = []\n",
        "    #length = []\n",
        "\n",
        "    for sentence in post:\n",
        "        sen_embedding = []\n",
        "        seq_len = len(sentence) -1\n",
        "        mask_seq = np.zeros(args.sequence_len, dtype = np.float32)\n",
        "        mask_seq[:len(sentence)] = 1.0\n",
        "        for i, word in enumerate(sentence):\n",
        "            sen_embedding.append(word_id_map.get(word, 0))\n",
        "\n",
        "        while len(sen_embedding) < args.sequence_len:\n",
        "            sen_embedding.append(0)\n",
        "\n",
        "        word_embedding.append(copy.deepcopy(sen_embedding))\n",
        "        mask.append(copy.deepcopy(mask_seq))\n",
        "        #length.append(seq_len)\n",
        "    return word_embedding, mask\n",
        "\n",
        "def load_data(args):\n",
        "    train, validate, test = process_data.get_data(args.text_only)\n",
        "    #print(train[4][0])\n",
        "    word_vector_path = '/content/drive/MyDrive/Colab Notebooks/EANN - (src에 코드)/Data/coupang/word_embedding.pickle'\n",
        "    f = open(word_vector_path, 'rb')\n",
        "    weight = pickle.load(f)  # W, W2, word_idx_map, vocab\n",
        "    W, W2, word_idx_map, vocab, max_len = weight[0], weight[1], weight[2], weight[3], weight[4]\n",
        "    args.vocab_size = len(vocab)\n",
        "    args.sequence_len = max_len\n",
        "    print(\"translate data to embedding\")\n",
        "\n",
        "    word_embedding, mask = word2vec(validate['post_text'], word_idx_map, W)\n",
        "    validate['post_text'] = word_embedding\n",
        "    validate['mask'] = mask\n",
        "\n",
        "\n",
        "    print(\"translate test data to embedding\")\n",
        "    word_embedding, mask = word2vec(test['post_text'], word_idx_map, W)\n",
        "    test['post_text'] = word_embedding\n",
        "    test['mask']=mask\n",
        "    #test[-2]= transform(test[-2])\n",
        "    word_embedding, mask = word2vec(train['post_text'], word_idx_map, W)\n",
        "    train['post_text'] = word_embedding\n",
        "    train['mask'] = mask\n",
        "    print(\"sequence length \" + str(args.sequence_length))\n",
        "    print(\"Train Data Size is \"+str(len(train['post_text'])))\n",
        "    print(\"Finished loading data \")\n",
        "    return train, validate, test, W\n",
        "\n",
        "def transform(event):\n",
        "    matrix = np.zeros([len(event), max(event) + 1])\n",
        "\n",
        "    #print(\"Translate  shape is \" + str(matrix))\n",
        "    for i, l in enumerate(event):\n",
        "        matrix[i, l] = 1.00\n",
        "    return matrix\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parse = argparse.ArgumentParser()\n",
        "    parser = parse_arguments(parse)\n",
        "    train = '/content/drive/MyDrive/Colab Notebooks/EANN - (src에 코드)/Data/coupang/train_id.pickle'\n",
        "    test = '/content/drive/MyDrive/Colab Notebooks/EANN - (src에 코드)/Data/coupang/test.pickle'\n",
        "    output = '/content/drive/MyDrive/Colab Notebooks/EANN - (src에 코드)/Data/coupang/output/'\n",
        "    args = parser.parse_args([train, test, output])\n",
        "\n",
        "    main(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e453852e",
      "metadata": {
        "id": "e453852e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}